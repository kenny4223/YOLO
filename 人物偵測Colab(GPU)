!pip install mediapipe

import cv2
import time
import os # è™•ç†æª”æ¡ˆè·¯å¾‘ï¼Œç”¨æ–¼æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨ (å·²ç§»è‡³ä¸Šæ–¹)
import numpy as np
import urllib.request
import mediapipe as mp
from google.colab.patches import cv2_imshow # Colab å°ˆç”¨çš„é¡¯ç¤ºå‡½å¼
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# --- æ­¥é©Ÿ 1: è¨­å®šèˆ‡æ¨¡å‹ä¸‹è¼‰ (MediaPipe) ---

# è¨­ç½®æ¨¡å‹æª”æ¡ˆåç¨±
POSE_LANDMARKER_MODEL = 'pose_landmarker_full.task'
# ä¿®æ­£ URLï¼šä½¿ç”¨æ›´ç©©å®šä¸”é€šç”¨çš„ Google Cloud Storage è·¯å¾‘
MODEL_URL = 'https://storage.googleapis.com/mediapipe-files/' + POSE_LANDMARKER_MODEL

# ä¸‹è¼‰æ¨¡å‹ï¼ˆå¦‚æœå°šæœªå­˜åœ¨ï¼‰
try:
    if not os.path.exists(POSE_LANDMARKER_MODEL):
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ MediaPipe å§¿å‹¢åœ°æ¨™æ¨¡å‹: {POSE_LANDMARKER_MODEL}...")
        # å¢åŠ è¶…æ™‚æ™‚é–“ä»¥æ‡‰å°è¼ƒæ…¢çš„ä¸‹è¼‰é€Ÿåº¦
        urllib.request.urlretrieve(MODEL_URL, POSE_LANDMARKER_MODEL, timeout=30)
        print("âœ… æ¨¡å‹ä¸‹è¼‰å®Œæˆã€‚")
except Exception as e:
    print(f"âŒ æ¨¡å‹ä¸‹è¼‰å¤±æ•—: {e}")
    # å¦‚æœä¸‹è¼‰å¤±æ•—ï¼Œå¯èƒ½æ˜¯ç¶²è·¯å•é¡Œæˆ–è·¯å¾‘å†æ¬¡è®Šå‹•
    print("è«‹æª¢æŸ¥æ‚¨çš„ç¶²è·¯é€£ç·šï¼Œæˆ–ç¢ºèªæ¨¡å‹è·¯å¾‘æ˜¯å¦ä»ç„¶æœ‰æ•ˆã€‚")
    exit()

# æ­¥é©Ÿ 2: åˆå§‹åŒ– MediaPipe å§¿å‹¢åœ°æ¨™å™¨ (Pose Landmarker)
# å°‡ running_mode è¨­ç‚º VIDEO æ‰èƒ½åœ¨é€£çºŒçš„å¹€ä¸­è™•ç†ä¸¦é€²è¡Œè¿½è¹¤ã€‚
BaseOptions = mp.tasks.BaseOptions
PoseLandmarker = mp.tasks.vision.PoseLandmarker
PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions
VisionRunningMode = mp.tasks.vision.RunningMode

options = PoseLandmarkerOptions(
    base_options=BaseOptions(model_asset_path=POSE_LANDMARKER_MODEL),
    running_mode=VisionRunningMode.VIDEO,
    # è¨­ç½®è¿½è¹¤äººæ•¸ä¸Šé™
    num_poses=5
)

# ä½¿ç”¨ with èªå¥ç¢ºä¿ Landmarker è³‡æºè¢«æ­£ç¢ºé‡‹æ”¾ (åœ¨ Colab äº’å‹•ç’°å¢ƒä¸­ï¼Œé€šå¸¸ç›´æ¥å‰µå»ºå³å¯)
landmarker = PoseLandmarker.create_from_options(options)

# è¨­ç½®è¼¸å…¥å’Œè¼¸å‡ºè·¯å¾‘ (å‡è¨­å½±ç‰‡å·²ç¶“ä¸Šå‚³åˆ° Colab æ ¹ç›®éŒ„)
video_path = "v4.mp4"
output_path = "v4_mediapipe_output.mp4"

cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"âŒ å½±ç‰‡è®€å–å¤±æ•—ï¼Œè«‹ç¢ºèªæª”æ¡ˆ {video_path} å·²ä¸Šå‚³ã€‚")
    exit()

# ç²å–å½±ç‰‡çš„åŸå§‹è³‡è¨Š
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
# ç²å–ç¸½å¹€æ•¸ (ç”¨æ–¼ timeStampMs è¨ˆç®—)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# æ­¥é©Ÿ 3: åˆå§‹åŒ–å½±ç‰‡å¯«å…¥å™¨ (VideoWriter)
# ä½¿ç”¨ mp4v ç·¨ç¢¼ï¼Œç¢ºä¿å¤šæ•¸æ’­æ”¾å™¨éƒ½èƒ½æ’­æ”¾
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

print(f"âœ… å½±ç‰‡å¯«å…¥å™¨åˆå§‹åŒ–æˆåŠŸï¼Œç›®æ¨™ FPS: {fps:.2f}")

# MediaPipe ç¹ªåœ–å·¥å…·
mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose
# è¨­å®šç¹ªè£½æ¨£å¼
drawing_styles = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)

frame_count = 0
start_time = time.time()

while True:
    ret, frame = cap.read()

    if not ret:
        break

    # è¨ˆç®— MediaPipe è¦æ±‚çš„ timeStampMs (ä»¥æ¯«ç§’ç‚ºå–®ä½)
    # é€™æ˜¯ MediaPipe é€²è¡Œå½±ç‰‡æ¨¡å¼è¿½è¹¤æ‰€å¿…éœ€çš„
    timestamp_ms = int((frame_count * 1000) / fps)

    # æ­¥é©Ÿ 4: è½‰æ›æ ¼å¼ä¸¦é€²è¡Œåµæ¸¬èˆ‡è¿½è¹¤
    # OpenCV è®€å–ç‚º BGRï¼ŒMediaPipe è¦æ±‚ RGB
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    mp_image = mp.Image(image_format=mp.ImageFormat.RGB, data=rgb_frame)

    # åŸ·è¡Œåµæ¸¬å’Œè¿½è¹¤
    detection_result = landmarker.detect_for_video(mp_image, timestamp_ms)

    # æ­¥é©Ÿ 5: ç¹ªè£½çµæœ (å§¿å‹¢éª¨æ¶å’Œäººç‰©è¨ˆæ•¸ ID)
    if detection_result.pose_landmarks:
        for idx, landmarks in enumerate(detection_result.pose_landmarks):
            # 1. ç¹ªè£½å§¿å‹¢éª¨æ¶ (MediaPipe çš„ä¸»è¦è¼¸å‡º)
            mp_drawing.draw_landmarks(
                frame,
                landmarks,
                mp_pose.POSE_CONNECTIONS,
                drawing_styles,
                drawing_styles
            )

            # 2. æ¨™è¨»äººç‰© ID (ä½¿ç”¨ç•¶å‰å¹€ä¸­çš„åµæ¸¬é †åºä½œç‚º ID)
            # æ³¨æ„: æ­¤ ID (idx) æ˜¯æ¯ä¸€å¹€ä¸­åµæ¸¬åˆ°çš„é †åºï¼Œè€Œéåƒ ByteTrack é‚£æ¨£çš„æŒçºŒæ€§è¿½è¹¤ IDã€‚
            # MediaPipe åœ¨ VIDEO æ¨¡å¼ä¸‹æœƒç›¡åŠ›ç¶­æŒå€‹é«”è¿½è¹¤ï¼Œä½†ä¸æœƒåœ¨çµæœä¸­æ˜ç¢ºæä¾› track_id æ¬„ä½ã€‚

            # æ‰¾å‡ºè¿‘ä¼¼çš„ Bounding Box é ‚é» (å¾æ‰€æœ‰åœ°æ¨™ä¸­è¨ˆç®— min/max åº§æ¨™)
            # ç”±æ–¼åœ°æ¨™åº§æ¨™æ˜¯æ­¸ä¸€åŒ–çš„ (0åˆ°1)ï¼Œéœ€è¦ä¹˜ä¸Šå¯¬é«˜ä¾†å¾—åˆ°åƒç´ å€¼
            x_min = min([lm.x * width for lm in landmarks])
            y_min = min([lm.y * height for lm in landmarks])

            # åœ¨é ­éƒ¨ä¸Šæ–¹æ¨™è¨» ID
            cv2.putText(
                frame,
                f"Person ID: {idx + 1}",
                (int(x_min), int(y_min) - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 0),
                2
            )

    # å°‡è™•ç†å¾Œçš„å¹€å¯«å…¥æ–°çš„å½±ç‰‡æª”æ¡ˆ
    out.write(frame)
    frame_count += 1

# æ­¥é©Ÿ 6: é‡‹æ”¾è³‡æºä¸¦è¨ˆç®—ç¸½ FPS
cap.release()
out.release()
# é—œé–‰ Landmarker é‡‹æ”¾æ¨¡å‹è³‡æº
landmarker.close()

end_time = time.time()
total_time = end_time - start_time
actual_fps = frame_count / total_time

print(f"ğŸ å½±ç‰‡è™•ç†å®Œæˆï¼ç¸½å¹€æ•¸: {frame_count}")
print(f"ç¸½è€—æ™‚: {total_time:.2f} ç§’")
print(f"å¹³å‡è™•ç† FPS: {actual_fps:.2f} FPS")
print(f"âœ… è™•ç†å¾Œçš„å½±ç‰‡å·²å„²å­˜ç‚º {output_path}ï¼Œè«‹ä¸‹è¼‰æª”æ¡ˆï¼")
