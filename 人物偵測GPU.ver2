# =========================================================
# æ­¥é©Ÿ 1: å®‰è£ã€å°å…¥èˆ‡æª”æ¡ˆè·¯å¾‘è¨­å®š
# =========================================================
print("--- æ­¥é©Ÿ 1/3: è¨­ç½®ç’°å¢ƒèˆ‡è·¯å¾‘è¨­å®š ---")

# ç¢ºä¿æ‚¨å·²ç¶“åœ¨çµ‚ç«¯æ©Ÿä¸­åŸ·è¡Œé: pip install ultralytics opencv-python

# å°å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡çµ„
import cv2
import torch
import time
from ultralytics import YOLO
import os 
import sys 

# --- æœ¬æ©Ÿæª”æ¡ˆè·¯å¾‘è¨­å®š (å¿…ä¿®æ”¹!) ---
# âš ï¸ é€™è£¡å¿…é ˆä¿®æ”¹ç‚ºæ‚¨é›»è…¦ä¸Šå½±ç‰‡çš„ã€çµ•å°è·¯å¾‘ã€‘æˆ–ã€ç›¸å°è·¯å¾‘ã€‘
# ç¯„ä¾‹ (Windows): "D:\\MyVideos\\input_video.mp4"
# ç¯„ä¾‹ (macOS/Linux): "/Users/YourName/Videos/input_video.mp4"
video_path = "D:\\MyVideos\\input_video.mp4"  # <-- è«‹å°‡æ­¤è™•æ›¿æ›ç‚ºæ‚¨çš„å½±ç‰‡è·¯å¾‘
output_path = "output_tracked_video.mp4" 

# æª¢æŸ¥è¼¸å…¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
if not os.path.exists(video_path):
    print(f"âŒ éŒ¯èª¤: åœ¨æŒ‡å®šè·¯å¾‘æ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆ: {video_path}")
    print("è«‹ä¿®æ”¹ç¨‹å¼ç¢¼ä¸­çš„ video_path è®Šæ•¸ç‚ºæ­£ç¢ºçš„æœ¬æ©Ÿè·¯å¾‘ã€‚")
    sys.exit()

print(f"âœ… è®€å–å½±ç‰‡è·¯å¾‘: {video_path}")
print(f"âœ… è¼¸å‡ºå½±ç‰‡å°‡å„²å­˜è‡³: {os.path.abspath(output_path)}")


# --- æ¨¡å‹èˆ‡ç¡¬é«”è¨­å®š ---
# è¼‰å…¥ YOLOv8 nano æ¨¡å‹
model = YOLO('yolov8n.pt') 

# è¨­ç½®è£ç½® (æœ¬æ©Ÿé‹è¡Œæ™‚ï¼Œå¦‚æœæ²’æœ‰ CUDAï¼Œæœƒè‡ªå‹•ä½¿ç”¨ CPU)
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
print(f"âœ… ä½¿ç”¨çš„è£ç½®: {device}")

# æ¨¡å‹è¼¸å…¥å°ºå¯¸
INFERENCE_IMG_SIZE = 320
print(f"ğŸ“ æ¨¡å‹è¼¸å…¥å°ºå¯¸: {INFERENCE_IMG_SIZE}x{INFERENCE_IMG_SIZE}")


# =========================================================
# æ­¥é©Ÿ 2: YOLOv8 å½±ç‰‡è™•ç†è¿´åœˆ (åªä¿ç•™ Process FPS)
# =========================================================
print("\n--- æ­¥é©Ÿ 2/3: å½±ç‰‡è™•ç†èˆ‡è¿½è¹¤ (å°‡å½ˆå‡ºå³æ™‚è¦–çª—) ---")

# è®€å–å½±ç‰‡æª”
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("âŒ å½±ç‰‡è®€å–å¤±æ•—ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æˆ–è·¯å¾‘æ˜¯å¦æ­£ç¢ºã€‚")
    sys.exit()

# ç²å–å½±ç‰‡å±¬æ€§
original_fps = cap.get(cv2.CAP_PROP_FPS)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
print(f"ğŸ¬ å½±ç‰‡åŸå§‹å°ºå¯¸: {frame_width}x{frame_height}, åŸå§‹ FPS: {original_fps:.2f}")

# å½±ç‰‡è¼¸å‡ºè¨­ç½®
fourcc = cv2.VideoWriter_fourcc(*'mp4v') 
# ç‚ºäº†é¿å…ç·¨ç¢¼å™¨å•é¡Œï¼Œè¼¸å‡º FPS æš«æ™‚è¨­ç‚º 30ï¼Œæ‚¨å¯ä»¥æ ¹æ“šéœ€è¦èª¿æ•´
out = cv2.VideoWriter(output_path, fourcc, original_fps, (frame_width, frame_height)) 

if not out.isOpened():
    print("âŒ è­¦å‘Šï¼šå½±ç‰‡å¯«å…¥å™¨é–‹å•Ÿå¤±æ•—ï¼Œè«‹æª¢æŸ¥æ˜¯å¦å®‰è£äº†æ­£ç¢ºçš„ç·¨ç¢¼å™¨ (ä¾‹å¦‚ FFmpeg)ã€‚")
    
# åˆå§‹åŒ–ç”¨æ–¼è¨ˆç®— FPS çš„è®Šæ•¸
prev_time = time.time() 
frame_count = 0 
total_start_time = time.time() 
processing_fps = 0.0

print("â³ é–‹å§‹é«˜é€Ÿè™•ç†å½±ç‰‡... (æŒ‰ 'q' éµé€€å‡ºï¼ŒæŒ‰ ' ' éµæš«åœ)")

paused = False # æ–°å¢æš«åœç‹€æ…‹è®Šæ•¸
window_name = "YOLOv8 Object Tracking (Local)"
cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)

while True:
    
    current_time = time.time()
    
    if not paused:
        ret, frame = cap.read()
        
        if not ret:
            print("\nğŸ¥ å½±ç‰‡æ’­æ”¾çµæŸ")
            break # å½±ç‰‡æ’­æ”¾çµæŸ
                
        # --- åŸ·è¡Œ YOLOv8 è¿½è¹¤ ---
        results = model.track(frame, 
                              classes=[0], 
                              tracker='bytetrack.yaml', 
                              conf=0.6,
                              imgsz=INFERENCE_IMG_SIZE,
                              verbose=False)
        
        # --- è¨ˆç®— Process FPS (æ•´é«”è™•ç†é€Ÿåº¦) ---
        elapsed_time = current_time - prev_time 
        processing_fps = 1 / elapsed_time if elapsed_time > 0 else 0 
        prev_time = current_time 

        # --- ç•«æ¡† ---
        for result in results:
            if result.boxes.id is not None:
                boxes = result.boxes.xyxy.cpu().numpy().astype(int)
                track_ids = result.boxes.id.cpu().numpy().astype(int)
                
                for box, track_id in zip(boxes, track_ids):
                    x1, y1, x2, y2 = box
                    color = (0, 255, 0)
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    cv2.putText(frame, f"ID: {track_id}", (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        # ç¹ªè£½ FPS è³‡è¨Šåˆ°å¹€ä¸Š
        cv2.putText(frame, f"FPS: {processing_fps:.2f}", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        if out.isOpened():
             out.write(frame)

        frame_count += 1 
    
    # --- é¡¯ç¤ºèˆ‡æŒ‰éµè™•ç† ---
    if 'frame' in locals():
        cv2.imshow(window_name, frame)
    
    # cv2.waitKey(1) å¿…é ˆä¿ç•™ï¼Œç”¨æ–¼é¡¯ç¤ºç•«é¢å’Œè™•ç†æŒ‰éµäº‹ä»¶
    key = cv2.waitKey(1) & 0xFF 
    
    if key == ord(' '): 
        paused = not paused
        if paused:
            print("â¸ï¸ å½±ç‰‡æš«åœã€‚")
        else:
            print("â–¶ï¸ å½±ç‰‡ç¹¼çºŒæ’­æ”¾ã€‚")
            
    if key == ord('q'): 
        break

# --- è³‡æºé‡‹æ”¾èˆ‡ç¸½çµ FPS ---
cap.release()
if out.isOpened():
    out.release() 
    print(f"\nâœ… è¼¸å‡ºå½±ç‰‡å·²å„²å­˜è‡³æœ¬æ©Ÿ: {os.path.abspath(output_path)}")

cv2.destroyAllWindows() # é—œé–‰æ‰€æœ‰ OpenCV è¦–çª—

total_end_time = time.time()
total_time = total_end_time - total_start_time

if frame_count > 0:
    average_fps = frame_count / total_time
    print("\n-------------------------------------------------")
    print(f"ç¸½å¹€æ•¸: {frame_count}")
    print(f"ç¸½è€—æ™‚: {total_time:.2f} ç§’")
    print(f"ğŸš€ **å¹³å‡è™•ç† FPS: {average_fps:.2f} FPS**")
    print("-------------------------------------------------")
else:
    print("âŒ å½±ç‰‡è™•ç†å¤±æ•—ï¼Œç„¡æ³•è¨ˆç®—å¹³å‡ FPSã€‚")


# =========================================================
# æ­¥é©Ÿ 3: å®Œæˆ (æœ¬æ©ŸåŸ·è¡Œï¼Œä¸éœ€ä¸‹è¼‰)
# =========================================================
print("\nğŸ‰ ç¨‹å¼æ‰€æœ‰æ­¥é©ŸåŸ·è¡Œå®Œç•¢ã€‚è«‹æª¢æŸ¥è¼¸å‡ºè·¯å¾‘ä¸‹çš„å½±ç‰‡æª”æ¡ˆã€‚")
